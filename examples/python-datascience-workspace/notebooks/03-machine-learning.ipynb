{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Machine Learning\n",
    "\n",
    "This notebook demonstrates predictive modeling with scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ML libraries loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and merge data\n",
    "customers = pd.read_csv('../data/customers.csv')\n",
    "sales = pd.read_csv('../data/sales.csv')\n",
    "\n",
    "# Aggregate sales per customer\n",
    "customer_sales = sales.groupby('customer_id').agg({\n",
    "    'amount': ['sum', 'mean', 'count'],\n",
    "    'quantity': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "customer_sales.columns = ['customer_id', 'total_spent', 'avg_sale', 'transaction_count', 'total_quantity']\n",
    "\n",
    "# Merge with customer data\n",
    "df = customers.merge(customer_sales, on='customer_id', how='left').fillna(0)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target variable: High-value customer (top 25% spenders)\n",
    "threshold = df['total_spent'].quantile(0.75)\n",
    "df['high_value'] = (df['total_spent'] >= threshold).astype(int)\n",
    "\n",
    "print(f\"High-value threshold: ${threshold:.2f}\")\n",
    "print(f\"High-value customers: {df['high_value'].sum()} ({df['high_value'].mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "le_city = LabelEncoder()\n",
    "df['city_encoded'] = le_city.fit_transform(df['city'])\n",
    "\n",
    "# Select features\n",
    "features = ['age', 'city_encoded', 'transaction_count', 'avg_sale', 'total_quantity']\n",
    "X = df[features]\n",
    "y = df['high_value']\n",
    "\n",
    "print(\"Features selected:\")\n",
    "for f in features:\n",
    "    print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Random Forest Results:\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from Random Forest\n",
    "importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=importance, x='importance', y='feature')\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "plt.show()\n",
    "\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Logistic Regression\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "axes[0].set_title('Logistic Regression')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "\n",
    "# Random Forest\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens', ax=axes[1])\n",
    "axes[1].set_title('Random Forest')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Compare models\n",
    "models = {\n",
    "    'Logistic Regression': y_pred_lr,\n",
    "    'Random Forest': y_pred_rf\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, preds in models.items():\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, preds),\n",
    "        'Precision': precision_score(y_test, preds),\n",
    "        'Recall': recall_score(y_test, preds),\n",
    "        'F1-Score': f1_score(y_test, preds)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(rf, '../data/high_value_customer_model.pkl')\n",
    "joblib.dump(scaler, '../data/scaler.pkl')\n",
    "\n",
    "print(\"Model saved to data/high_value_customer_model.pkl\")\n",
    "print(\"Scaler saved to data/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "1. **Best Model**: Random Forest achieved highest accuracy\n",
    "2. **Top Features**: Transaction count and average sale amount\n",
    "3. **Business Insight**: High-value customers make frequent purchases\n",
    "4. **Model Deployment**: Saved and ready for predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
